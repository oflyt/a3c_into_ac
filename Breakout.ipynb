{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code builds on the code provided by Jaromir Janisch, 2017\n",
    "\n",
    "# OpenGym CartPole-v0 with A3C on GPU\n",
    "# -----------------------------------\n",
    "#\n",
    "# A3C implementation with GPU optimizer threads.\n",
    "# \n",
    "# Made as part of blog series Let's make an A3C, available at\n",
    "# https://jaromiru.com/2017/02/16/lets-make-an-a3c-theory/\n",
    "#\n",
    "# author: Jaromir Janisch, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable memory growth for GPU on Windows machines\n",
    "Disable this cell if you are not on Windows or if you run on CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "session = tf.Session(config=config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dimensions(env):\n",
    "    \"\"\"Calculate dimensions based on the environment\n",
    "    Halves the width and height and removes the color dimensions. \n",
    "    \"\"\"\n",
    "    n_actions = env.action_space.n\n",
    "    obs_shape = env.observation_space.shape\n",
    "    height = obs_shape[0]//2; width = obs_shape[1]//2; n_frames = 4\n",
    "    state_shape = (height, width, n_frames)\n",
    "    return (state_shape, n_actions)\n",
    "\n",
    "def start(threads):\n",
    "    \"Helper method for starting threads\"\n",
    "    for thread in threads:\n",
    "        thread.daemon=True\n",
    "        thread.start()\n",
    "\n",
    "def stop(threads):\n",
    "    \"Helper method for stopping threads\"\n",
    "    for thread in threads:\n",
    "        thread.stop()\n",
    "    for thread in threads:\n",
    "        try:\n",
    "            thread.join()\n",
    "        except:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym, time, random\n",
    "import queue\n",
    "\n",
    "from ai_agent import Agent\n",
    "from ai_environment import Environment\n",
    "from ai_brain import Brain\n",
    "from ai_optimizer import Optimizer\n",
    "from util_plotter import Plotter\n",
    "from util_persistence import Persister\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "It is important to chose the correct amount of agents and optimizers.  \n",
    "More agents usually means more stable learning becuase of the diversity in observations.  \n",
    "To few optimizers will lead to too big batches, too many optimizers leads to redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = 'BreakoutDeterministic-v4'\n",
    "RUN_TIME = 24*60*60\n",
    "AGENTS = 10\n",
    "OPTIMIZERS = 5\n",
    "weights_name = \"data/testing_code.h5\"\n",
    "rewards_file = 'data/testing_code.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Shapes \n",
    "state_shape, actions_shape = calc_dimensions(gym.make(ENV))\n",
    "\n",
    "# Rewards\n",
    "global rewards\n",
    "db = Persister(rewards_file)\n",
    "rewards = db.read()\n",
    "\n",
    "# Brain\n",
    "brain = Brain(state_shape, actions_shape, model_weights=weights_name)\n",
    "\n",
    "# Threads\n",
    "exception_bucket = queue.Queue()\n",
    "envs = [Environment(\n",
    "            gym.make(ENV), \n",
    "            rewards, \n",
    "            Agent(brain, actions_shape, len(rewards)), \n",
    "            exception_bucket) \n",
    "        for i in range(AGENTS)]\n",
    "\n",
    "opts = [Optimizer(brain, exception_bucket) for i in range(OPTIMIZERS)]\n",
    "plotters = [Plotter(rewards, Agent(brain, actions_shape, len(rewards)))]\n",
    "\n",
    "# Main\n",
    "try:\n",
    "    start(opts); start(envs); start(plotters)\n",
    "    \n",
    "    # Sleep for shorter periods to enable KeyBoardInterrupt\n",
    "    for i in range(0, RUN_TIME, 15):\n",
    "        time.sleep(15)\n",
    "        \n",
    "        if i % 40 == 0:\n",
    "            brain.save_weights(weights_name)\n",
    "            db.write(rewards) \n",
    "            \n",
    "        # Shutdown if there was an exception in agent or optimizer\n",
    "        try:\n",
    "            e = exception_bucket.get(block=False)\n",
    "            raise e\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "            \n",
    "finally:\n",
    "    stop(envs); stop(opts); stop(plotters)\n",
    "    brain.save_weights(weights_name)\n",
    "    db.write(rewards) \n",
    "    \n",
    "    print(\"Training finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
